from enum import Enum
import logging
import os
from typing import List, Type
import pydantic

from wemg.agents.roles.base_role import BaseLLMRole

logger = logging.getLogger(__name__)
logger.setLevel(os.getenv("LOGGING_LEVEL", "INFO"))

EXTRACT_PROMPT = """You are a meticulous and insightful research analyst. Your primary objective is to build a comprehensive dossier of all information from the provided text that could help a user fully understand and answer their question. You prioritize thoroughness, context, and nuance. You must think step-by-step to ensure no helpful detail, however tangential, is overlooked.

## Instructions: 
- Step 1: Question Deconstruction: First, carefully analyze the user's Question. Identify and list the primary subject, all key entities (people, organizations, concepts), and the specific information or insight the user is seeking. This is your 'search brief'.
- Step 2: Candidate Identification: Next, read the entire Raw Data and identify and quote ALL passages that seem potentially related to the concepts from Step 1. Be liberal and inclusive in this initial pass; we will filter and refine in the next step. If no passages appear even remotely related, state this and proceed to Step 5.
- Step 3: Systematic Relevance Evaluation: Now, for each candidate passage quoted in Step 2, you must perform a systematic evaluation. Iterate through each quote and assess it against the following criteria: Directly Answering, Contextual, Supporting Evidence, Methodological, Alternative Perspectives, Related Concepts, Implications, Enrichment, Entities. For each candidate quote, you must state exactly which criterion (or criteria) it meets and provide a one-sentence justification for your assessment. If a quote meets no criteria, mark it as 'Not Relevant'.
- Step 4: Extraction: Extract ALL relevant information. Ensure the extraction is strictly verbatim and includes full sentences to preserve context. If an extraction is deemed relevant but it is lacks context or clarity, you should add additional context to ensure clarity and self-containment (i.e., Each extraction must be FULLY UNDERSTANDABLE on its own without needing to refer back to the original document or question) but make sure that you DO NOT add any information that was not present in the original document and MAKE SURE TO KEEP THE ORIGINAL MEANING INTACT. If no passages were deemed relevant, this section should be left empty.
- Step 5: Final Decision: Based on your analysis in the preceding steps, state your final decision: 'relevant' or 'not_relevant'. A document is only 'not_relevant' if it contains ZERO information that could relate to any entity or concept in the question. If it contains even a single piece of information that could be relevant, it is 'relevant', even if it is not directly answering the question. Refine your extractions against this final decision. If you decide the document is 'relevant', ensure that your extractions are comprehensive and contain all information that could help answer the question. If you decide the document is 'not_relevant', ensure that your extractions are empty.
"""

class ExtractionInput(pydantic.BaseModel):
    question: str = pydantic.Field(..., description="The user's question.")
    raw_data: str = pydantic.Field(..., description="The raw text data to be analyzed.")

    def __str__(self):
        return "\n\n".join([f"{key}:\n{value}" for key, value in self.model_dump().items()])

class ExtractionOutput(pydantic.BaseModel):
    information: List[str] = pydantic.Field(
        ...,
        description="A list of extracted information from the data that is relevant to the question"
    )
    decision: str = pydantic.Field(
        ...,
        pattern=r"^(relevant|not_relevant)$",
        description="The decision on whether the data is relevant to the question."
    )
    reasoning: str = pydantic.Field(
        ...,
        description="A explanation of the thought process behind the extractions, detailing how the information was identified as relevant or not and why it was extracted."
    )


class Extractor(BaseLLMRole):
    name = "extractor"
    description = "Information extraction role for multi-hop question answering."

    def __init__(
            self,
            system_prompt: str = EXTRACT_PROMPT,
            input_model: Type[pydantic.BaseModel] = ExtractionInput,
            output_model: Type[pydantic.BaseModel] = ExtractionOutput
    ):
        super().__init__(system_prompt, input_model, output_model)


class SourceType(Enum):
    SYSTEM_PREDICTION = "System Prediction"   # information generated by the system itself
    RETRIEVAL = "Retrieval"               # information retrieved from external sources

MEMORY_CONSOLIDATION_PROMPT = """You are an expert Memory Consolidation Agent. Your task is to process an input memory (a list of tagged information items) and consolidate it into a refined memory that contains only the information relevant and useful for answering the given question.

## Provenance Tags
- [System Prediction]: Information generated by the system itself (inferences, hypotheses, intermediate conclusions)
- [Retrieval]: Information retrieved from external sources (knowledge bases, documents, web search)

## Core Objective
Transform raw memory into a clean, non-redundant, question-focused memory that maximizes utility for answering the specific question.

## Step-by-Step Instructions

### Step 1: Question Analysis
Analyze the question to identify and list the primary subject, all key entities (e.g., people, organizations, concepts), and the specific information or insight being sought.

### Step 2: Relevance Filtering
For each memory item, assess its relevance to answering the question:
- **Directly Relevant**: Provides facts needed to answer the question
- **Supporting**: Provides context or bridges between facts
- **Irrelevant**: Does not contribute to answering the question â†’ REMOVE

### Step 3: Duplicate & Redundancy Removal
Among relevant items:
- Remove exact duplicates (keep [Retrieval] over [System Prediction] if both exist)
- Merge near-duplicates into single comprehensive items
- Remove items whose information is subsumed by other items

### Step 4: Conflict Resolution
For contradictory items:
- [Retrieval] takes precedence over [System Prediction]
- More specific takes precedence over general
- If unresolvable, merge into an item that notes the conflict

### Step 5: Final Consolidation
Each item MUST be self-contained and clear, i.e., understandable without any external context, referencing the original memory, question, or other items

## Critical Rules
- You MUST NOT invent new information not present in the input memory
- You MUST NOT remove provenance tags
- You MUST remove information irrelevant to answering the question
- You MUST preserve all relevant, non-redundant information
- You MUST NOT alter the factual meaning of any information
"""


class MemoryConsolidationInput(pydantic.BaseModel):
    question: str = pydantic.Field(
        ..., 
        description="The question that the consolidated memory should help answer."
    )
    memory: str = pydantic.Field(
        ..., 
        description="The raw memory to consolidate, formatted as a list of tagged items (each starting with [System Prediction] or [Retrieval])."
    )

    def __str__(self):
        return "\n\n".join([f"{key}:\n{value}" for key, value in self.model_dump().items()])


class MemoryItem(pydantic.BaseModel):
    content: str = pydantic.Field(
        ...,
        description="The piece of information from memory, which is self-contained and understandable on its own."
    )
    provenance: SourceType = pydantic.Field(
        ...,
        pattern=r"^(System Prediction|Retrieval)$",
        description="The provenance tag indicating the source of the information."
    )

class MemoryConsolidationOutput(pydantic.BaseModel):
    consolidated_memory: List[MemoryItem] = pydantic.Field(
        ...,
        description="The refined list of memory items that are relevant and useful for answering the question."
    )
    reasoning: str = pydantic.Field(
        ...,
        description="Brief explanation of what was kept, removed, or merged and why."
    )

class MemoryConsolidationRole(BaseLLMRole):
    name = "memory_consolidation"
    description = "Role for consolidating textual memory relevant to a question."

    def __init__(
            self,
            system_prompt: str = MEMORY_CONSOLIDATION_PROMPT,
            input_model: Type[pydantic.BaseModel] = MemoryConsolidationInput,
            output_model: Type[pydantic.BaseModel] = MemoryConsolidationOutput
    ):
        super().__init__(system_prompt, input_model, output_model)



