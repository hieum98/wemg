from enum import Enum
import logging
import os
from typing import List
import networkx as nx

from wemg.agents import roles
from wemg.agents.base_llm_agent import BaseLLMAgent

logger = logging.getLogger(__name__)
logger.setLevel(os.getenv("LOGGING_LEVEL", "INFO"))


class SourceType(Enum):
    SYSTEM_CONCLUSION = "SYSTEM_CONCLUSION" # conclusion generated by the system
    WEB_RETRIEVAL = "WEB_RETRIEVAL"         # information retrieved from web search
    KB_RETRIEVAL = "KB_RETRIEVAL"           # information retrieved from knowledge

class Memory:
    def __init__(
            self,
            textual_memory: List[str],
            graph_memory: nx.Graph,
            max_textual_memory_tokens: int = 8192,
    ):  
        self.entity_dict = {} # mapping from open_ie.Entity to wikidata.WikidataEntity
        self.textual_memory = textual_memory
        self.graph_memory = graph_memory

        self.max_textual_memory_tokens = max_textual_memory_tokens
    
    def add_textual_memory(self, text: str, source: SourceType=SourceType.SYSTEM_CONCLUSION):
        """Add text to textual memory if not already present."""
        if source == SourceType.SYSTEM_CONCLUSION:
            text = f"[System Conclusion]: {text}"
        elif source == SourceType.WEB_RETRIEVAL:
            text = f"[Web Retrieval]: {text}"
        elif source == SourceType.KB_RETRIEVAL:
            text = f"[Knowledge Base Retrieval]: {text}"
        if text not in self.textual_memory:
            self.textual_memory.append(text)

    def format_textual_memory(self) -> str:
        """Format the textual memory as a single string."""
        memory = [f"- {text.strip()}" for text in self.textual_memory]
        return "\n".join(memory)

    def consolidate_textual_memory(self, llm_agent: BaseLLMAgent, question: str):
        
        extractor_role = roles.extractor.Extractor()
        extractor_input = roles.extractor.ExtractionInput(
            question=question,
            raw_data=self.format_textual_memory()
        )
        memory_consolidation_messages = extractor_role.format_messages(input_data=extractor_input)

    def remove_textual_memory(self):
        pass
    
    def update_textual_memory(self):
        pass

    def add_graph_node(self):
        pass

    def add_graph_edge(self):
        pass

    def remove_graph_node(self):
        pass

    def remove_graph_edge(self):
        pass

    def update_graph_node(self):
        pass

    def update_graph_edge(self):
        pass

    def consolidate_graph_memory(self):
        pass


    
    

